% TEMPLATE for Usenix papers, specifically to meet requirements of
%  USENIX '05
% originally a template for producing IEEE-format articles using LaTeX.
%   written by Matthew Ward, CS Department, Worcester Polytechnic Institute.
% adapted by David Beazley for his excellent SWIG paper in Proceedings,
%   Tcl 96
% turned into a smartass generic template by De Clarke, with thanks to
%   both the above pioneers
% use at your own risk.  Complaints to /dev/null.
% make it two column with no page numbering, default is 10 point

% Munged by Fred Douglis <douglis@research.att.com> 10/97 to separate
% the .sty file from the LaTeX source template, so that people can
% more easily include the .sty file into an existing document.  Also
% changed to more closely follow the style guidelines as represented
% by the Word sample file. 

% Note that since 2010, USENIX does not require endnotes. If you want
% foot of page notes, don't include the endnotes package in the 
% usepackage command, below.

% This version uses the latex2e styles, not the very ancient 2.09 stuff.
\documentclass[letterpaper,twocolumn,10pt]{article}
\usepackage{usenix,epsfig,endnotes}
\usepackage{amsfonts}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}


\begin{document}

%don't want date printed
\date{}

%make title bold and 14 pt font (Latex default is non-bold, 16 pt)
\title{\Large \bf Implementing and Benchmarking a LWE-based Fully Homomorphic Encryption Scheme}

%for single author (just remove % characters)
\author{
{\rm Meghan L.\ Clark}\\
University of Michigan
\and
{\rm Alex L.\ James}\\
University of Michigan
\and
{\rm Travis B.\ Martin}\\
University of Michigan
} % end author

\maketitle

% Comment this out for page numbers, 
% put it back in for no numbers.
%\thispagestyle{empty}


%DONE -- REQUIRES FILL-IN-THE-BLANK
\abstract{
Fully homomorphic encryption (FHE) provides a way for third parties to compute arbitrary functions on encrypted data. This has the potential to revolutionize cloud computing services. Unfortunately, since their emergence in 2009, FHE schemes have become notorious for incurring enormous costs in time and space. Over the last four years optimizations have been proposed with impressive rapidity. However, these improvements are usually only asymptotically beneficial. The newness of the field and relative opacity of the literature has resulted in few implementations and evaluations of actual performance. To fill this gap, we implement a recent FHE scheme based on the Learning with Errors (LWE) hardness problem. We compare the performance of our system with an implementation of an earlier FHE scheme based on the Approximate GCD (AGC) hardness problem. We find that the LWE scheme performs [BETTER/WORSE] than the AGCD scheme. We release our system to the public to promote additional experimentation and to increase the accessibility of this new cryptographic construct.
}

%INCOMPLETE
\section{Introduction}
Fully homomorphic encryption (FHE) is a cryptographic scheme where any function can be computed on encrypted data, and the decrypted result will be the correct answer.

FHE has profound implications for cloud computing services. The security and privacy concerns associated with providing your data to a third party are eliminated, as they will never see your decrypted data, and neither will anyone who compromises their system. Some applications of this are with medical records - hard to get a hold of, run statistics on, but no longer. Satellites - no longer need to trust a third party to keep secrets. Private search queries. Private location-based-services. Secure voting.

Unfortunately, in their current state, FHE schemes incur too much overhead to be used in actual applications. Even in some extremely recent examples, such as evaluating AES-128 encrpytion where they increased performance by orders of magnitude, the process required over three days to complete and 256 GB of RAM\cite{AES}. 

Since the first FHE scheme was proposed in 2009, combatting the performance costs has been the primary focus of the FHE research community. They propose many optimizations, but mostly asymptotic results. Since they are theory folks and optimizations are coming out so rapidly, there have been few implementations. However, this means that it is hard to gauge whether or not optimizations that are asymptotically faster represent actual performance improvements. Without this feedback, it's hard to tell which branch of FHE to pursue.

Recently a scheme was proposed by Brakerski, Gentry, and Vaikuntanathan in \cite{SansBootstrapping} that involves a new branch of FHE based on LWE that is able to operate without bootstrapping. The authors state explicity that while their solutions are asymptotically faster, they don't know whether or not they're actually faster in practice than earlier schemes:

\begin{quotation}
``Performance-wise, this scheme trounces previous (bootstrapping-based) FHE schemes (at least asymptotically; the concrete performance remains to be seen)."
\end{quotation}

We answer this call by implementing it and comparing it to a bootstrapping AGCD-based scheme by Coron, Naccache, and Tibouchi. This comparison adds to the sparse set of real-world FHE performance data points. We are also the first to release LWE FHE code to the public. This can be used for additional paramter exploration, cracking attempts, or a hands-on introduction to an FHE system.


%DONE
\section{Background}
In this section we provide a brief history and an explanation of the mechanics of the two main FHE schemes. This will provide the background required for understanding the FHE implementations that we evaluate.

%DONE
\subsection{Circuits}
The goal of FHE is to be able to perform arbitrary computations on ciphertext, such that the decrypted result is the same as the result of performing the same computations on the plaintext.

To be capable of arbitrary computation, the cryptosystem need only support two operations, which we will call addition and multiplication, such that
$$D_k(E_k(m_1) + E_k(m_2)) = m_1 + m_2$$
$$D_k(E_k(m_1) * E_k(m_2)) = m_1 * m_2$$
where $E$ and $D$ are the encryption and decryption functions.

It has been shown elsewhere that supporting these two operations provides Turing completeness. However, for an intuitive explanation, consider that your computer can run arbitrary programs, yet all of the logical circuits in the hardware can be theoretically implementing using just AND and XOR gates. 

For this reason, in the FHE literature all functions to be computed on ciphertext are called ``circuits" and are constructed as nested binary operations, such as $(E_k(1)+((E_k(1)*E_k(0)+E_k(1))$.

Following suit, throughout the rest of this paper we assume that the operands $m_1$ and $m_2$ are single bits (either $0$ or $1$), and we assume that the addition and multiplication operations are equivalent to binary addition (XOR) and binary multiplication (AND).

%DONE
\subsection{Partial Homomorphism}
Cryptographic schemes that support just one of the two necessary operations are called \emph{partially homomorphic}. The possiblity of FHE was first suggested after examining the partially homomorphic properties of RSA in 1978~\cite{Rivest}, although an actual FHE scheme was not successfullly devised until over thirty years later.

A cryptographic scheme that supports two operations but only for a limited number of successive operations is called \emph{somewhat homomorphic}. A somewhat homomorphic encryption (SWHE) scheme was crucial to the development of the first FHE scheme.

%DONE
\subsection{Lattices}
The first working FHE scheme was proposed in 2009 by Craig Gentry~\cite{GentryThesis09, GentrySTOC09}. The system was based on a mathematical construct called lattices. In particular, the security of the scheme rested on the hardness of solving certain problems using lattices. However, this system was so complicated and difficult to understand that it immediately gave way to equivalent yet more intuitive integer-based schemes~\cite{SmartVercauteren, DGHV} which we will describe in detail in the next section.

Though the FHE literature quickly shifted away from representing ciphertext and keys using lattices, it is worth noting that all current FHE schemes can still ultimately trace their security back to lattice-based hardness problems. 

%INCOMPLETE
\subsection{Approximate GCD Schemes}
A year after Gentry described the first FHE scheme, he released a second scheme that translated his lattice-based system into an integer-based system whose security relied on the Approximate GCD hardness problem~\cite{DGHV}. This system spawned a family of related AGCD schemes that tweak or optimize Gentry's original scheme.

Gentry described a three-step process for constructing a fully homomorphic scheme. First he began with a SWHE scheme. However, as his thesis points out, when your system can evaluate its own decryption circuit, you become powerful enough to indefinitely compute. Which is what we want, however, as the scheme is only somewhat homomorphic it is the case that its decryption circuit is too complicated and requires too much nose introduction through multiplications. So the second step is to ``squash'' the decryption circuit by transforming the problem from its current encrypted space into a smaller encrypted space with much less complexity. After this is done it is possible to homomorphically decrypt the ciphertext to refresh the noise, effectively bootstraping the result into a much smaller noise range for more computation.

\subsubsection{Somewhat Homomorphic \\Encryption Scheme} 
First, we begin with the somewhat homomorphic design over the integers. Consider the encryption scheme $E_k(m) = m + 2e + pq$ where the private key $q leftarrow G(1^\lambda)$, $p < q$ an odd integer and the noise term $e << p$. Then this scheme will encrypt a single bit message which can be recovered with the decryption scheme $D_k(c) = (c \bmod p) \bmod 2$.

One can see that both addition satisfies the homomorphism property that we are after; doing so with very minimal noise increase.
$$E_k(m_1)+E_k(m_2)=m1+m2 + 2(e_1+e_2) + p(q_1+q_2)$$

Similarly, multiplication also has this property, but with a caveat attached. By multiplying our ciphertexts we have also multiplied our error terms together, in very few multiplication steps, this error can grow out of control and quickly dwarf $p$. Once this happens, decryption fails as the number wraps around $\bmod p$

It is important to note that the security of this scheme is directly replated to the difficulty of the Approximate Greatest Common Divisor problem, a problem which states that given $n$ near divisors of $p$ it is still difficult to compute $p$ if $p$ is relatively large.

Start with SWHE scheme (describe. You can use the real public key, the real encryption with the zeros from the public key if you want, the decryption function, etc. Get mathy!). Mention AGCD hardness assumption.

\subsubsection{Squashing the decryption circuit}
So we are able to do many additions, but only a few multiplications due to exponential growth. It is therefore necissary to ``squash'' the decryption circuit. The standard way to approach squashing this particular scheme is to give hints to the private key in the form of $E_p(p)$ and a Sparse Subset Sum problem involving $\frac{1}{p}$. With this additional information, homomorphic decryption becomes much more accessible and has a much smaller circuit.

\subsubsection{Bootstrapping}
What exactly does the decryption circuit look like? Remember that the traditional way to represent the decryption circuit for this scheme was with
$$m = (m + 2e + pq \bmod p) \bmod 2$$
However, we can not have the third party directly computing $\bmod p$ as that would entirely reveal our secret key $p$. Instead this modular arithmetic can be phrased as $c- p\floor{\frac{c}{p}} = m + 2e$. Finally, after noticing that we can see then, $m = LSB(m + 2e) = LSB(c) - LSB(p\floor{\frac{c}{p}}) = m$. If it is possible to provide the necissary information for this method without revealing information about the private key, then it is possible to homomorphically decrypt.

As mentioned above, this is done though the sparse subset problem. Encrypt values into a large encrypted vector $S$ which has a very sparse subset summing to $\frac{1}{p}$. Next, construct a secret vector $v$ such that $v_i = E_p(0)$ if the $i^{th}$ element of $S$ is not used in the sparse subset and $v_i = E_p(1)$ if it is. Notice that $S.v = E_p(\frac{1}{p})$, however the third party does not know which subset of either vector was used in the computation.

With this information the third party is able to evaluate the homomorphic decryption circuit without having to compute $\frac{1}{p}$, reducing the number of computations, and so the depth of the circuit.

\subsubsection{Problems}
Gentry's bootstrapping theorem was key to creating a FHE scheme from a SWHE scheme. Unfortunately, there are many downsides to bootstrapping. The most costly downside is that bootstrapping is a very expensive operation in general. It requires a large amount of time to run\cite{ImplementingGentry} and also can lead to large ciphertexts. Even with this in mind, many of the early families of fully homomorphic encryption schemes bootstrapped after every operation due to the large amount of noise introduced by their multiplication operations. There have been several recent advancements in implementations using bootstrapping\cite{StehleSteinfeld, SmartVercauteren, ImplementingGentry, CNT} but the research community has also focused intently on removing the necessity for bootstrapping entirely such as in Learning with Errors, the scheme that was implemented by this paper.

%INCOMPLETE
\subsection{Learning With Errors Schemes}
\label{sec:lwe}
In addition to AGCD-based schemes, another family of schemes arose which made intuitive sense. Using a similar form to the AGCD-based scheme, the Learning with Errors Schemes\cite{SansBootstrapping} schemes viewed their ciphertext as randomly chosen vectors dotted and added with a secret key.
$$E_s(m) = (a, <a,s> + 2e + m)$$
$$D_c(x) = (<a,s> + 2e + m) - <a,x>$$

The Learning with Errors problem is a very powerful problem to base cryptographic constructions on. It is rather famous for being as hard as worst-case lattice problems, allowing all constructions based soley on it to be secure under the assumption that worst-case lattice problems are hard.

In this scheme, addition of two ciphertexts is done in the same way that addition would naively be done, however, when looking at the multiplication it is helpful to look at the invarient linear function $\phi(x) \equiv b - <a,x>$ and multiply these instead. When this is done it takes the key from dimension $n$ to dimension $n^2$ and so to maintain managable key sizes for even small circuit depth a relinearization step is necissary. For this to happen, it is necissary for the client to post encryptions of pairwise multiples of their secret key's entries. Luckily, the rings we are dealing with are communitive and so it is only necissary to post $E(s[i]s[j])$ for $0 \leq i \leq j \leq n$ where $s[0] \doteq 1$. This allows transformation from a keyspace in $s$ of degree $n^2$ to a second keyspace for a secret key $t$ of size $n$. If we assume circular security, then we can simply publish this transformation rather than a large chain of transformations and $s$ will then re-encrypt to itself.

However, this does not negate the impact of noise, as the chain progresses, the noise will grow. To handle the noise it is helpful to observe the ratio between the noise $B$ and the modulus $q$. When $\frac{B}{q} \approx 1$ the noise overwhelms the message and so we prefer to have a small noise ratio. This is done with a well known property of modulus, if $ab \equiv ac \bmod ad$ then $b \equiv c \bmod d$. Just like in much of this work, we do not need exact precision as we are already dealing with an error term, instead we can approximate this effect even if
the terms do not divide as nicely. By doing this, we reduce the absolute value of the noise from $B^2$ after a multiplication back down to $B$. This allows us to evaluate $L$ depth circuits with modulus $q \geq B^L+1$ rather than having to require a modulus $q \geq B^{2^L}$. This method is called modulus reduction.

To lower the complexity of the decryption circuit a sufficient amount it is also necessary to lower the dimension of the ciphertext which we are dealing with. This is done with dimension reduction, one should note from the relinearization stage that it isn't necessary to have $s$ and $t$ be of the same dimension. Using this fact, it is possible to convert the ciphertext from using a private key $s$ of dimension $n$ to a private key $t$ of dimension $k$. After these steps have been performed our ciphertext will have reduced noise, and reduced complexity which allows for bootstrapping as an optimization.

The last statement might seem out of place to the reader, as bootstrapping was just described as being very inefficient. However, it can be an optimization if the depth of the circuit is large enough that evaluation on the high-dimension and high-modulus components becomes restrictive. In this case, evaluation on a smaller circuit with bootstrapping to refresh the noise would in fact be an optimization rather than a bottleneck.

Out implementation of the LWE scheme is as described above, in it we implement multiple optimizations to allow for quick computation of the circuit such as the modulus scaling property.


%INCOMPLETE
\section{Related Work}
There are a few implementations of FHE schemes that have been used in papers over the past four years. Specifically, implementations such as the evaluation of the 128-AES circuit\cite{AES} where the authors aimed to show that their scheme was powerful enough to handle the AES circuit, Implementing Gentry\cite{ImplementingGentry}, the ``Practical" paper\cite{Practical}, and the Coron and Scarab projects. All of these have implemented various FHE encryption schemes and have shown optimizations over previous versions while still having their drawbacks. For instance, bootstrapping taking between 30 seconds for small examples and 30 minutes for larger examples\cite{ImplementingGentry} and generation of the key scheduling taking 150 hours or evaluation timing out before even a single iteration is complete\cite{AES}. These implementations attempt to improve upon previous works and offer a quick benchmark for the possible implementation of the scheme before moving onto the next. We intend this project to provide a static point of reference for this scheme with hopes that future improvements can be easily added by either the authors or by third parties.

This section is for highlighting what makes our work different from previous work.


\section{Methodology}
We began this project with a thorough investigation of FHE schemes in general, theoretical attacks on insecure schemes, and hardness assumptions and security parameters that current schemes are being based on. With this detailed background we moved toward an implementation stage by taking an existing FHE implementation written in Python SAGE and evaluating its performance. For a fair comparison to this method we then implemented our own version of the standard LWE FHE encryption scheme, also in Python SAGE.

To establish test cases, it was necessary to observe the size of the security parameter in the AGCD implementation and establish an equivalent security parameter to run our LWE implementation with. The other parameters of our scheme, such as the dimension of the original secret key, the size of the modulus and the range of the error term are all determined by our security key in relations established by the implemented paper\cite{StandardLWE}. We then evaluated several test cases to benchmark our implementation against theirs using these parameters. These test cases are described in Section~\ref{sec:results}.

To emphasize the validity of our comparison, we note that both implementations were straightforward extensions of mathematically specified schemes from their respective papers. Further, each scheme was evaluated for the same set of security parameters, with additional parameters chosen to give the desired level of security. Additional parameters were chosen according to the provably secure ranges provided in \cite{StandardLWE, CNT}. Our tests were run in similar environments on the same computer. Due to these similarities, we reduce the possibility for performance differences to either differences in fundamental efficiency or differences in programming efficiency. These are discussed in Section~\ref{sec:results}.


%INCOMPLETE
\section{Implementation}
The code works in several stages. A user-level interface has been designed to support modifying the parameters used in the encryption process and parsing expression inputs for evaluation. The interface provides a simple and convenient way for users to verify that arbitrary functions can be applied to arbitrary inputs. In practice, function specification would be separate from data encryption so that multiple functions could be applied to the data at arbitrary points in time.

After the parser establishes the depth of the circuit, a list of public information is generated which transform the ciphertext between the necessary keys throughout the algorithm's multiple relinearization and dimension-modulus reduction operations.

All random variables are generated uniformly within an appropriate range, for instance, the error term is not allowed to be large relative to the modulus $q$ and so it was generated within $\log(q)$. This reinforces the hardness of the LWE problem by using the same parameter space that is used in the classical problem.

Once the public keys and supporting information have been generated, the circuit is evaluated. Throughout the process encryption and decryption are handled in the invariant form as elements of $\mathbb{Z}^n_q$ where multiplication is handled by a tensor product to $\mathbb{Z}^{n\times n}_q$ followed by relinearization back to elements of $\mathbb{Z}^n_q$ with degree less than $n$ and a modulus reduction to $\mathbb{Z}^k_p$ to reduce the noise incurred by a multiplication. This process is repeated until the final value has been computed. Modulus-dimension reduction and relinearization are both explained in Section~\ref{sec:lwe}, and optimizations proposed by Brakerski et al.~\cite{StandardLWE}. Once the final ciphertext is computed, our user-interface decrypts the result to verify that the circuit has been computed correctly.


\section{Results}
\label{sec:results}
Our implementation test consisted of two batteries of tests for varying security parameters. In the first, designed to compare our implementation to the implementation by Coron et al~\cite{CNT}, we analyze the running time for adding and multiplying one encrypted bit. All times include time to encrypt, perform the respective operation and decrypt. Their multiplication time also includes time for bootstrapping. Our multiplication time also includes time for relinearization and modulus-dimension reduction. We don't include these operations in the addition operation timings because they aren't required due to minimal noise increase. All parameters are chosen to give the level of security required by the security parameter, according to guidelines specified by the original authors. Timings can be found in Figure~\ref{fig:coron}. All tests were run on a Intel i7 2.67 GHz Quad Core processor with 24 GB of RAM.

As our figure shows, their performance is much greater for small security parameters. This is mainly due to the large difference in Sage programming experience between Coron et al. and the authors of this report. We believe there are many more efficient ways to express the polynomial operations we used, but we did not have time to optimize these operations. However, we see that, asymptotically, our implementation outperforms theirs. For large security parameters, the inherent efficiency advantage of learning with errors over approximate gcd becomes apparent. Additionally, we see that, in the limit of large security parameter, their addition and multiplication operations take about the same time. This is because the time of encrypting extremely large ciphertexts swamps the time required for bootstrapping. In the learning with errors based scheme, contrarily, multiplication remains approximately twice as slow as addition, even in the limit of large ciphertexts.

Our second set of tests attempts to analyze the efficiency of our scheme for deeper circuits. We first show that our scheme scales well - executing functions with several multiplications and additions takes only a little bit more time than performing one multiplication alone. Secondly, we find that deeper circuits, requiring more modulus-dimension reduction, are not necessarily slower than circuits with more operations. Results for the second set of tests can be found in Figure~\ref{fig:depth}.


%INCOMPLETE
\section{Discussion}
The results that we encountered were not exactly what we were hoping for, especially in a code version released to the public, they do demonstrate one of the hardships of creating a fully homomorphic cryptographic system; it is necessary to understand the language which you are working in fully to take advantage of all optimizations available and to avoid all pitfalls.

Although our implementation fell short of its hopeful goal when being compared against the AGCD version, we feel that this is not an indictment of the LWE system but more a display of the level of optimizations that have been placed into the AGCD program which will be necessary to replicate in our future implementation of the LWE program.

It should be noted however that our code does scale better with increased security parameters (fortunately this is where cryptography is done). This is a very good indication that LWE is indeed an asymptotically better solution than AGCD and we feel that further increasing the performance of our code will undoubtedly force the break even point much closer to the toy example given.

Can be short. Talk about the main results, particularly the impact. Were our results reasonable or surprising? Do our results mean that we should advocate for LWE or AGCD? Are they too close to call? Or are our results too specific to the implementations and optimizations used? When might we get different results?


%INCOMPLETE
\section{Future Work}
There are several goals for the future. For this specific code two main goals are to refine it into a more module and adaptable structure for easy modification by a third party for review and experimentation and to optimize it by relying more heavily on Sage structures and experimenting with the fastest methods to do specific tasks. There are also a few more optimizations such as determining minimalistic parameters based on the depth of the circuit. 

Further work can be done to implement and publish other forms of FHE encryption with their associated optimizations, forms such as the AGCD described above and the NTRU-like scheme.

Can be short. Stuff not only that you'd want to do on this project in the future, but what any FHE researcher might try next after having read this.


%INCOMPLETE
\section{Conclusion}
Despite the alacritous pace at which theoretical work is being done to improve the performance of fully homomorphic encryption, no one is doing sanity checks by implementing these schemes. This makes it difficult to know what actual progress is being made and which directions are most promising. To address this deficit, we implemented a LWE-based FHE scheme in Python and Sage and compared it to an existing implementation of an AGCD-based FHE scheme, also written in Python and Sage. We found that the LWE implementation performed [BETTER? To WHAT DEGREE?] than the AGCD implementation. In addition to expanding the corpus of FHE performance benchmarks, we also publicly release our code. We hope that this work helps provide direction to future FHE research and increases the accessibility of this new and exciting area of cryptography.


%DONE
\section{Availability}
We feel that releasing our implementation to the public for examination and experimentation is one of the major contributions of this work. Our code and directions for running it can be found at:

\begin{center}
{\tt https://github.com/tbmbob/bootstraplessfhe}\\
\end{center}

If you have questions, we will do our best to answer them.

%INCOMPLETE
{\footnotesize \bibliographystyle{acm}
\bibliography{final_paper}

% this is at the end so it can be one column, on its own page
\begin{figure}[t]
\begin{center}
\onecolumn
\begin{tabular}{|c|c|c|c|c|c|} \hline
Example size & Security Parameter & Their add (s) & Their mult (s) & Our add (s) & Our mult (s) \\ \hline
Toy & 42 & .048 & .560 & 18.0 & 35.9 \\ \hline
Small & 52 & 3.38 & 7.37 & 48.9 & 98.6 \\ \hline
Medium & 62 & 71 & 106 & 110.3 & 225.1 \\ \hline
Large & 72 & 1460 & 1860 & 249 & 524.3 \\ \hline
\end{tabular}
\end{center}
\caption{Timing: Coron et al. implementation vs. our LWE-based implementation, for varying security parameters}
\label{fig:coron}
\end{figure}

\begin{figure}[t]
\begin{center}
\begin{tabular}{|c|c|c|c|} \hline
Example size & Security Parameter & 11 operations, depth 1 (s) & 7 operations, depth 2 (s) \\ \hline
Toy & 42 & 42.5 & 39.4 \\ \hline
Small & 52 & 109.3 & 109.5 \\ \hline
Medium & 62 & 251.0 & 251.1 \\ \hline
\end{tabular}
\end{center}
\caption{Timing: our LWE-based implementation for varying numbers of operations, depth}
\label{fig:depth}
\end{figure}

\end{document}
